{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structural Query for *De Novo* Binder Design\n",
    "\n",
    "This Jupyter Notebook performs a structural query to identify optimal PDB structures for *de novo* protein binder design. The pipeline consists of multiple steps:\n",
    "\n",
    "1. **Setup** – Import necessary libraries, define constants, and initialize functions.\n",
    "2. **Search** – Query the RCSB PDB database to retrieve membrane protein structures that meet specific criteria.\n",
    "3. **Filtering** – Process search results and remove structures that do not meet quality standards.\n",
    "4. **Processing** – Analyze filtered structures to identify suitable truncations and hydrophobic hotspots.\n",
    "5. **Output** – Generate and store the final dataset in JSON format, including relevant visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "The first section initializes the notebook by:\n",
    "- Importing required **libraries** (e.g., `logging`, `urllib3`, `json`, `matplotlib`, `seaborn`, `sparqlwrapper`, and `biopython`).\n",
    "- Defining **global constants** (e.g., API endpoints, filtering queries, color scheme).\n",
    "- Implementing **utility functions** to handle HTTP requests, data processing, and visualization.\n",
    "\n",
    "The conda environment configuration is specified in `conda.yml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT MODULES\n",
    "\n",
    "import logging\n",
    "import urllib3\n",
    "import urllib.parse\n",
    "import json\n",
    "from typing import Any, cast\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib_set_diagrams import EulerDiagram\n",
    "import matplotlib.patheffects as path_effects\n",
    "\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from Bio.PDB import PDBList, FastMMCIFParser, Structure, is_aa, alphafold_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GLOBAL CONSTANTS\n",
    "\n",
    "DEFAULT_CLIENT = urllib3.PoolManager()\n",
    "\n",
    "API_ENDPOINT = {\n",
    "    \"rcsb/search\": \"https://search.rcsb.org/rcsbsearch/v2/query\",\n",
    "    \"rcsb/data\": \"https://data.rcsb.org/graphql\",\n",
    "    \"rcsb/entry\": \"https://data.rcsb.org/rest/v1/core/entry\",\n",
    "    \"rcsb/assembly\": \"https://data.rcsb.org/rest/v1/core/assembly\",\n",
    "    \"rcsb/entity/branched\": \"https://data.rcsb.org/rest/v1/core/branched_entity\",\n",
    "    \"rcsb/entity/polymer\": \"https://data.rcsb.org/rest/v1/core/polymer_entity\",\n",
    "    \"rcsb/entity/non-polymer\": \"https://data.rcsb.org/rest/v1/core/non-polymer_entity\",\n",
    "    \"uniprot/search\": \"https://rest.uniprot.org/uniprotkb/stream\",\n",
    "    \"uniprot/data\": \"https://sparql.uniprot.org/sparql\",\n",
    "    \"uniprot/features\": \"https://www.ebi.ac.uk/proteins/api/features\",\n",
    "    \"alphafold/entry\": \"https://alphafold.ebi.ac.uk/api/prediction\"\n",
    "}\n",
    "\n",
    "RCSB_SEARCH_QUERY = {\n",
    "    \"query\": {\n",
    "        \"type\": \"terminal\",\n",
    "        \"service\": \"text\"\n",
    "    },\n",
    "    \"request_options\": {\n",
    "        \"results_verbosity\": \"compact\",\n",
    "        \"return_all_hits\": True\n",
    "    },\n",
    "    \"return_type\": \"entry\"\n",
    "}\n",
    "\n",
    "RCSB_DATA_QUERY = {\n",
    "    \"query\": \"\"\"\n",
    "    query($ids: [String!]!) {\n",
    "        entries(entry_ids: $ids) {\n",
    "            entry {\n",
    "                id\n",
    "            }\n",
    "            citation {\n",
    "                pdbx_database_id_DOI\n",
    "            }\n",
    "            rcsb_entry_info {\n",
    "                polymer_entity_count\n",
    "                polymer_entity_count_protein\n",
    "                resolution_combined\n",
    "            }\n",
    "            polymer_entities {\n",
    "                entity_poly {\n",
    "                    pdbx_seq_one_letter_code_can\n",
    "                    rcsb_sample_sequence_length\n",
    "                }\n",
    "                rcsb_polymer_entity_container_identifiers {\n",
    "                    entity_id\n",
    "                }\n",
    "                rcsb_polymer_entity_container_identifiers {\n",
    "                    asym_ids\n",
    "                    auth_asym_ids\n",
    "                    uniprot_ids\n",
    "                }\n",
    "                rcsb_polymer_entity_feature {\n",
    "                    type\n",
    "                    name\n",
    "                    feature_id\n",
    "                    feature_positions {\n",
    "                        beg_seq_id\n",
    "                        end_seq_id\n",
    "                        values\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \"\"\",\n",
    "    \"variables\": dict()\n",
    "}\n",
    "\n",
    "UNIPROT_DATA_QUERY = \"\"\"\n",
    "    PREFIX up: <http://purl.uniprot.org/core/>\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "\n",
    "    SELECT (?protein AS ?uniprot)\n",
    "        (GROUP_CONCAT(DISTINCT ?entry; SEPARATOR=\", \") AS ?rcsb)\n",
    "        (GROUP_CONCAT(DISTINCT ?alphafold; SEPARATOR=\", \") AS ?alphafold)\n",
    "        (GROUP_CONCAT(DISTINCT ?annotationtype; SEPARATOR=\", \") AS ?annotations)\n",
    "\n",
    "    WHERE {\n",
    "        VALUES (?entry) { $entries }\n",
    "        BIND (IRI(CONCAT(\"http://purl.uniprot.org/pdbsum/\", ?entry)) AS ?pdb)\n",
    "\n",
    "        ?protein a up:Protein .\n",
    "        ?protein rdfs:seeAlso ?pdb .\n",
    "        ?pdb up:database <http://purl.uniprot.org/database/PDBsum> .\n",
    "\n",
    "        OPTIONAL { \n",
    "            ?protein rdfs:seeAlso ?alphafold . \n",
    "            ?alphafold up:database <http://purl.uniprot.org/database/AlphaFoldDB> . \n",
    "        }\n",
    "\n",
    "        OPTIONAL {\n",
    "            ?protein up:annotation ?annotation . \n",
    "            ?annotation rdf:type ?annotationtype .\n",
    "        }\n",
    "    }\n",
    "\n",
    "    GROUP BY ?protein\n",
    "\"\"\"\n",
    "\n",
    "UNIPROT_FEATURES_QUERY = {\n",
    "    \"size\": -1,\n",
    "    \"types\": \",\".join([\"TOPO_DOM\", \"TRANSMEM\", \"HELIX\", \"TURN\", \"STRAND\"])\n",
    "}\n",
    "\n",
    "TUM_BLUE_GRADIENT = \"blend:#0A2D57,#3070B3,#E3EEFA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GLOBAL VARIABLES\n",
    "\n",
    "result = {\n",
    "    \"search\": dict(),\n",
    "    \"filter\": dict(),\n",
    "    \"summary\": dict(),\n",
    "    \"data\": dict()\n",
    "}\n",
    "\n",
    "data = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FUNCTIONS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search\n",
    "\n",
    "The **search step** queries **PDB structures** based on predefined selection criteria.  \n",
    "Each retrieved PDB entry must satisfy the following conditions:\n",
    "\n",
    "- **Membrane proteins**: structure must belong to a membrane protein as annotated by common membrane protein databases.\n",
    "- **Taxonomy**: protein must originate from *Drosophila melanogaster* or *Homo sapiens*.\n",
    "- **Acquisition method**: only Electron Microscopy (EM) structures are considered.\n",
    "- **Resolution**: 3.5 Å or better (i.e., resolution ≤ 3.5 Å).\n",
    "- **Journal**: original citation for the structure must originate from specific journals.\n",
    "- **Composition**: structure must belong to a homomeric or heteromeric protein.\n",
    "- **Multimericity**: only **monomeric proteins** are selected (polimeric count = 1).\n",
    "\n",
    "Intersection of the described search subsets forms the final search result set of PDB entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SEARCH: ANNOTATION\n",
    "\n",
    "RCSB_SEARCH_QUERY[\"query\"][\"parameters\"] = {\n",
    "    \"attribute\": \"rcsb_polymer_entity_annotation.type\",\n",
    "    \"operator\": \"in\",\n",
    "    \"value\": [\n",
    "        \"PDBTM\",\n",
    "        \"MemProtMD\",\n",
    "        \"OPM\",\n",
    "        \"mpstruc\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = DEFAULT_CLIENT.request(\n",
    "    method=\"POST\",\n",
    "    url=API_ENDPOINT[\"rcsb/search\"],\n",
    "    json=RCSB_SEARCH_QUERY\n",
    ")\n",
    "\n",
    "if response.status == 200:\n",
    "    result[\"search\"][\"annotation\"] = json.loads(response.data.decode(\"utf8\"))[\"result_set\"]\n",
    "else:\n",
    "    logging.error(\"Failed to query RCSB search API\")\n",
    "    logging.error(response.data.decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SEARCH: ORGANISM\n",
    "\n",
    "RCSB_SEARCH_QUERY[\"query\"][\"parameters\"] = {\n",
    "    \"attribute\": \"rcsb_entity_source_organism.taxonomy_lineage.name\",\n",
    "    \"operator\": \"in\",\n",
    "    \"value\": [\n",
    "        \"Drosophila melanogaster\",\n",
    "        \"Mus musculus\",\n",
    "        \"Homo sapiens\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = DEFAULT_CLIENT.request(\n",
    "    method=\"POST\",\n",
    "    url=API_ENDPOINT[\"rcsb/search\"],\n",
    "    json=RCSB_SEARCH_QUERY\n",
    ")\n",
    "\n",
    "if response.status == 200:\n",
    "    result[\"search\"][\"organism\"] = json.loads(response.data.decode(\"utf8\"))[\"result_set\"]\n",
    "else:\n",
    "    logging.error(\"Failed to query RCSB search API\")\n",
    "    logging.error(response.data.decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SEARCH: ACQUISITION METHOD\n",
    "\n",
    "RCSB_SEARCH_QUERY[\"query\"][\"parameters\"] = {\n",
    "    \"attribute\": \"exptl.method\",\n",
    "    \"operator\": \"exact_match\",\n",
    "    \"value\": \"ELECTRON MICROSCOPY\"\n",
    "}\n",
    "\n",
    "response = DEFAULT_CLIENT.request(\n",
    "    method=\"POST\",\n",
    "    url=API_ENDPOINT[\"rcsb/search\"],\n",
    "    json=RCSB_SEARCH_QUERY\n",
    ")\n",
    "\n",
    "if response.status == 200:\n",
    "    result[\"search\"][\"acquisition\"] = json.loads(response.data.decode(\"utf8\"))[\"result_set\"]\n",
    "else:\n",
    "    logging.error(\"Failed to query RCSB search API\")\n",
    "    logging.error(response.data.decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SEARCH: RESOLUTION\n",
    "\n",
    "RCSB_SEARCH_QUERY[\"query\"][\"parameters\"] = {\n",
    "    \"attribute\": \"rcsb_entry_info.resolution_combined\",\n",
    "    \"operator\": \"less_or_equal\",\n",
    "    \"value\": 3.5\n",
    "}\n",
    "\n",
    "response = DEFAULT_CLIENT.request(\n",
    "    method=\"POST\",\n",
    "    url=API_ENDPOINT[\"rcsb/search\"],\n",
    "    json=RCSB_SEARCH_QUERY\n",
    ")\n",
    "\n",
    "if response.status == 200:\n",
    "    result[\"search\"][\"resolution\"] = json.loads(response.data.decode(\"utf8\"))[\"result_set\"]\n",
    "else:\n",
    "    logging.error(\"Failed to query RCSB search API\")\n",
    "    logging.error(response.data.decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SEARCH: JOURNAL\n",
    "\n",
    "# RCSB_SEARCH_QUERY[\"query\"][\"parameters\"] = {\n",
    "#     \"attribute\": \"rcsb_primary_citation.rcsb_journal_abbrev\",\n",
    "#     \"operator\": \"in\",\n",
    "#     \"value\": [\n",
    "#         \"Nat Struct Mol Biol\",\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# response = DEFAULT_CLIENT.request(\n",
    "#     method=\"POST\",\n",
    "#     url=API_ENDPOINT[\"rcsb/search\"],\n",
    "#     json=RCSB_SEARCH_QUERY\n",
    "# )\n",
    "\n",
    "# if response.status == 200:\n",
    "#     result[\"search\"][\"journal\"] = json.loads(response.data.decode(\"utf8\"))[\"result_set\"]\n",
    "# else:\n",
    "#     logging.error(\"Failed to query RCSB search API\")\n",
    "#     logging.error(response.data.decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SEARCH: COMPOSITION\n",
    "\n",
    "RCSB_SEARCH_QUERY[\"query\"][\"parameters\"] = {\n",
    "    \"attribute\": \"rcsb_entry_info.polymer_composition\",\n",
    "    \"operator\": \"in\",\n",
    "    \"value\": [\n",
    "        \"heteromeric protein\",\n",
    "        \"homomeric protein\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = DEFAULT_CLIENT.request(\n",
    "    method=\"POST\",\n",
    "    url=API_ENDPOINT[\"rcsb/search\"],\n",
    "    json=RCSB_SEARCH_QUERY\n",
    ")\n",
    "\n",
    "if response.status == 200:\n",
    "    result[\"search\"][\"composition\"] = json.loads(response.data.decode(\"utf8\"))[\"result_set\"]\n",
    "else:\n",
    "    logging.error(\"Failed to query RCSB search API\")\n",
    "    logging.error(response.data.decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SEARCH: MULTIMERICITY\n",
    "\n",
    "RCSB_SEARCH_QUERY[\"query\"][\"parameters\"] = {\n",
    "    \"attribute\": \"rcsb_entry_info.deposited_polymer_entity_instance_count\",\n",
    "    \"operator\": \"equals\",\n",
    "    \"value\": 1\n",
    "}\n",
    "\n",
    "response = DEFAULT_CLIENT.request(\n",
    "    method=\"POST\",\n",
    "    url=API_ENDPOINT[\"rcsb/search\"],\n",
    "    json=RCSB_SEARCH_QUERY\n",
    ")\n",
    "\n",
    "if response.status == 200:\n",
    "    result[\"search\"][\"multimericity\"] = json.loads(response.data.decode(\"utf8\"))[\"result_set\"]\n",
    "else:\n",
    "    logging.error(\"Failed to query RCSB search API\")\n",
    "    logging.error(response.data.decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMBINE SEARCH RESULTS\n",
    "\n",
    "result[\"summary\"][\"search\"] = list(set.intersection(*map(set, result[\"search\"].values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "\n",
    "The PDB entries from the search are **filtered** to ensure high data quality.\n",
    "The filtering pipeline consists of multiple steps:\n",
    "\n",
    "- **Entity validation**: Ensure that each PDB entry contains*one and exactly one polymeric protein entity.\n",
    "- **Uniqueness check**: identify and retain only one representative structure per protein.\n",
    "- **Cross-references to UniProt**: verify that a unique UniProt accession is associated with each PDB entry.\n",
    "- **Cross-references to AlphaFoldDB**: ensure that the protein has a corresponding AlphaFold model.\n",
    "- **Hydropathy index**: check whether a hydropathy index is available for the protein.\n",
    "- **Disordered regions**: confirm that disordered regions are defined and annotated.\n",
    "- **Secondary structure**: ensure that secondary structure elements (e.g., α-helices, β-strands, turns) are annotated.\n",
    "- **Topology Information**: validate whether transmembrane, cytoplasmic, and extracellular annotations exist.\n",
    "\n",
    "Each of these filtering steps helps refine the dataset to contain only high-quality, well-annotated protein structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET RCSB DATA\n",
    "\n",
    "RCSB_DATA_QUERY[\"variables\"] = {\n",
    "    \"ids\": result[\"summary\"][\"search\"]\n",
    "}\n",
    "\n",
    "response = DEFAULT_CLIENT.request(\n",
    "    method=\"POST\",\n",
    "    url=API_ENDPOINT[\"rcsb/data\"],\n",
    "    json=RCSB_DATA_QUERY\n",
    ")\n",
    "\n",
    "if response.status == 200:\n",
    "    data[\"rcsb\"] = json.loads(response.data.decode(\"utf8\"))[\"data\"][\"entries\"]\n",
    "else:\n",
    "    logging.error(\"Failed to query RCSB data API\")\n",
    "    logging.error(response.data.decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "URITooLong",
     "evalue": "URITooLong: The URI requested by the client is longer than the server is willing to interpret. Check if the request was sent using GET method instead of POST method.. \n\nResponse:\nb\"<doctype html><html lang='en'/><head><title>Client error: 414 uri too long</title></head><body><h1>Client error 414 uri too long</h1></body></html>\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/structure-query/lib/python3.13/site-packages/SPARQLWrapper/Wrapper.py:926\u001b[0m, in \u001b[0;36mSPARQLWrapper._query\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 926\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43murlopener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturnFormat\n",
      "File \u001b[0;32m/opt/anaconda3/envs/structure-query/lib/python3.13/urllib/request.py:189\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, context)\u001b[0m\n\u001b[1;32m    188\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/structure-query/lib/python3.13/urllib/request.py:495\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    494\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 495\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/anaconda3/envs/structure-query/lib/python3.13/urllib/request.py:604\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 604\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/anaconda3/envs/structure-query/lib/python3.13/urllib/request.py:533\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    532\u001b[0m args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 533\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/structure-query/lib/python3.13/urllib/request.py:466\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    465\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 466\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/structure-query/lib/python3.13/urllib/request.py:613\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 613\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 414: Request-URI Too Long",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURITooLong\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m sparql\u001b[38;5;241m.\u001b[39msetQuery(UNIPROT_DATA_QUERY)\n\u001b[1;32m      9\u001b[0m sparql\u001b[38;5;241m.\u001b[39msetReturnFormat(JSON)\n\u001b[0;32m---> 11\u001b[0m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniprot\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], \u001b[43msparql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert())[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbindings\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/structure-query/lib/python3.13/site-packages/SPARQLWrapper/Wrapper.py:960\u001b[0m, in \u001b[0;36mSPARQLWrapper.query\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mquery\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryResult\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    943\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;124;03m    Execute the query.\u001b[39;00m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;124;03m    Exceptions can be raised if either the URI is wrong or the HTTP sends back an error (this is also the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;124;03m    :rtype: :class:`QueryResult` instance\u001b[39;00m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 960\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m QueryResult(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/structure-query/lib/python3.13/site-packages/SPARQLWrapper/Wrapper.py:936\u001b[0m, in \u001b[0;36mSPARQLWrapper._query\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Unauthorized(e\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m414\u001b[39m:\n\u001b[0;32m--> 936\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m URITooLong(e\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m    937\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m500\u001b[39m:\n\u001b[1;32m    938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m EndPointInternalError(e\u001b[38;5;241m.\u001b[39mread())\n",
      "\u001b[0;31mURITooLong\u001b[0m: URITooLong: The URI requested by the client is longer than the server is willing to interpret. Check if the request was sent using GET method instead of POST method.. \n\nResponse:\nb\"<doctype html><html lang='en'/><head><title>Client error: 414 uri too long</title></head><body><h1>Client error 414 uri too long</h1></body></html>\""
     ]
    }
   ],
   "source": [
    "### GET UNIPROT DATA\n",
    "\n",
    "UNIPROT_DATA_QUERY = UNIPROT_DATA_QUERY.replace(\n",
    "    \"$entries\", \" \".join(f\"('{id}')\" for id in result[\"summary\"][\"search\"])\n",
    ")\n",
    "\n",
    "sparql = SPARQLWrapper(API_ENDPOINT[\"uniprot/data\"])\n",
    "sparql.setQuery(UNIPROT_DATA_QUERY)\n",
    "sparql.setReturnFormat(JSON)\n",
    "\n",
    "data[\"uniprot\"] = cast(dict[str, Any], sparql.query().convert())[\"results\"][\"bindings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FILTER: REPRESENTATIVE\n",
    "\n",
    "result[\"filter\"][\"representative\"] = []\n",
    "mapping = dict()\n",
    "\n",
    "for protein in data[\"uniprot\"]:\n",
    "    accession = protein[\"uniprot\"][\"value\"]\n",
    "    entries = protein[\"rcsb\"][\"value\"].split(\", \")\n",
    "    representative = None\n",
    "    resolution = float(\"inf\")\n",
    "\n",
    "    for entry in entries:\n",
    "        info = next((elem for elem in data[\"rcsb\"] if elem[\"entry\"][\"id\"] == entry), None)\n",
    "\n",
    "        if info is None:\n",
    "            continue\n",
    "\n",
    "        if current := info[\"rcsb_entry_info\"][\"resolution_combined\"][0] < resolution:\n",
    "            resolution = current\n",
    "            representative = entry\n",
    "\n",
    "    if representative:\n",
    "        result[\"filter\"][\"representative\"].append(representative)\n",
    "        mapping[representative] = accession.split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FILTER: ENTITY\n",
    "\n",
    "result[\"filter\"][\"entity\"] = [\n",
    "    entry[\"entry\"][\"id\"]\n",
    "    for entry in data[\"rcsb\"]\n",
    "    if entry[\"rcsb_entry_info\"][\"polymer_entity_count\"] == 1\n",
    "    and entry[\"rcsb_entry_info\"][\"polymer_entity_count_protein\"] == 1\n",
    "    and all(entry[\"entry\"][\"id\"] in filter for filter in result[\"filter\"].values())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FILTER: UNIPROT\n",
    "\n",
    "result[\"filter\"][\"uniprot\"] = [\n",
    "    entry[\"entry\"][\"id\"]\n",
    "    for entry in data[\"rcsb\"]\n",
    "    if len([\n",
    "        reference for entity in entry[\"polymer_entities\"]\n",
    "        for reference in entity[\"rcsb_polymer_entity_container_identifiers\"][\"uniprot_ids\"]\n",
    "    ]) == 1\n",
    "    and all(entry[\"entry\"][\"id\"] in filter for filter in result[\"filter\"].values())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FILTER: ALPHAFOLD\n",
    "\n",
    "result[\"filter\"][\"alphafold\"] = [\n",
    "    entry\n",
    "    for protein in data[\"uniprot\"]\n",
    "    if \"alphafold\" in protein\n",
    "    for entry in protein[\"rcsb\"][\"value\"].split(\", \")\n",
    "    if entry in result[\"filter\"][\"representative\"]\n",
    "    and all(entry in filter for filter in result[\"filter\"].values())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FILTER: HYDROPATHY\n",
    "\n",
    "result[\"filter\"][\"hydropathy\"] = [\n",
    "    entry[\"entry\"][\"id\"]\n",
    "    for entry in data[\"rcsb\"]\n",
    "    if any(\n",
    "        feature[\"type\"] == \"hydropathy\"\n",
    "        for entity in entry[\"polymer_entities\"]\n",
    "        for feature in entity[\"rcsb_polymer_entity_feature\"]\n",
    "    )\n",
    "    and all(entry[\"entry\"][\"id\"] in filter for filter in result[\"filter\"].values())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FILTER: DISORDER\n",
    "\n",
    "result[\"filter\"][\"disorder\"] = [\n",
    "    entry[\"entry\"][\"id\"]\n",
    "    for entry in data[\"rcsb\"]\n",
    "    if any(\n",
    "        feature[\"type\"] == \"disorder\"\n",
    "        for entity in entry[\"polymer_entities\"]\n",
    "        for feature in entity[\"rcsb_polymer_entity_feature\"]\n",
    "    )\n",
    "    and all(entry[\"entry\"][\"id\"] in filter for filter in result[\"filter\"].values())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FILTER: SECONDARY STRUCTURE\n",
    "\n",
    "result[\"filter\"][\"structure\"] = [\n",
    "    entry\n",
    "    for protein in data[\"uniprot\"]\n",
    "    if all(annotation in protein[\"annotations\"][\"value\"]\n",
    "        for annotation in (\n",
    "            \"http://purl.uniprot.org/core/Beta_Strand_Annotation\", \n",
    "            \"http://purl.uniprot.org/core/Helix_Annotation\",\n",
    "            \"http://purl.uniprot.org/core/Turn_Annotation\"\n",
    "        ))\n",
    "    for entry in protein[\"rcsb\"][\"value\"].split(\", \")\n",
    "    if entry in result[\"filter\"][\"representative\"]\n",
    "    and all(entry in filter for filter in result[\"filter\"].values())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FILTER: TOPOLOGY\n",
    "\n",
    "result[\"filter\"][\"topology\"] = [\n",
    "    entry\n",
    "    for protein in data[\"uniprot\"]\n",
    "    if all(annotation in protein[\"annotations\"][\"value\"]\n",
    "        for annotation in (\n",
    "            \"http://purl.uniprot.org/core/Topological_Domain_Annotation\", \n",
    "            \"http://purl.uniprot.org/core/Transmembrane_Annotation\"\n",
    "        ))\n",
    "    for entry in protein[\"rcsb\"][\"value\"].split(\", \")\n",
    "    if entry in result[\"filter\"][\"representative\"]\n",
    "    and all(entry in filter for filter in result[\"filter\"].values())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMBINE FILTER RESULTS\n",
    "\n",
    "result[\"summary\"][\"filter\"] = list(set.intersection(*map(set, result[\"filter\"].values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET UNIPROT FEATURES\n",
    "\n",
    "accessions = [mapping[entry] for entry in result[\"summary\"][\"filter\"]]\n",
    "data[\"uniprot\"] = []\n",
    "\n",
    "for i in range(0, len(accessions), 100):\n",
    "    batch = accessions[i:i+100]\n",
    "    UNIPROT_FEATURES_QUERY[\"accession\"] = \",\".join(batch)\n",
    "\n",
    "    response = DEFAULT_CLIENT.request(\n",
    "        method=\"GET\",\n",
    "        url=API_ENDPOINT[\"uniprot/features\"] + \"?\" + urllib.parse.urlencode(UNIPROT_FEATURES_QUERY),\n",
    "        headers={\"Accept\": \"application/json\"}\n",
    "    )\n",
    "\n",
    "    if response.status == 200:\n",
    "        data[\"uniprot\"].extend(json.loads(response.data.decode(\"utf8\")))\n",
    "    else:\n",
    "        logging.error(\"Failed to query UniProt features API\")\n",
    "        logging.error(response.data.decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FETCH STRUCTURE FILES\n",
    "\n",
    "pdbl = PDBList(verbose=False)\n",
    "pdbl.download_pdb_files(\n",
    "    pdb_codes=result[\"summary\"][\"filter\"], pdir=\"./results/rcsb/\", file_format=\"mmCif\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET ALPHAFOLD DATA\n",
    "\n",
    "data[\"alphafold\"] = []\n",
    "\n",
    "for accession in accessions:\n",
    "    response = DEFAULT_CLIENT.request(\n",
    "        method=\"GET\",\n",
    "        url=API_ENDPOINT[\"alphafold/entry\"] + \"/\" + accession,\n",
    "        headers={\"Accept\": \"application/json\"}\n",
    "    )\n",
    "\n",
    "    if response.status == 200:\n",
    "        data[\"alphafold\"].extend(json.loads(response.data.decode(\"utf8\")))\n",
    "    else:\n",
    "        logging.error(\"Failed to query AlphaFold API\")\n",
    "        logging.error(response.data.decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FETCH ALPHAFOLD FILES\n",
    "\n",
    "for entry in data[\"alphafold\"]:\n",
    "    alphafold_db.download_cif_for(entry, \"./results/alphafold/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATA CURATION\n",
    "\n",
    "data[\"uniprot\"] = sorted(\n",
    "    [entry for entry in data[\"uniprot\"] if entry[\"accession\"] in accessions],\n",
    "    key=lambda entry: accessions.index(entry[\"accession\"])\n",
    ")\n",
    "\n",
    "data[\"rcsb\"] = sorted(\n",
    "    [entry for entry in data[\"rcsb\"] if entry[\"entry\"][\"id\"] in result[\"summary\"][\"filter\"]],\n",
    "    key=lambda entry: result[\"summary\"][\"filter\"].index(entry[\"entry\"][\"id\"])\n",
    ")\n",
    "\n",
    "data[\"alphafold\"] = sorted(\n",
    "    [entry for entry in data[\"alphafold\"] if entry[\"uniprotAccession\"] in accessions],\n",
    "    key=lambda entry: accessions.index(entry[\"uniprotAccession\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXTRACT FEATURES\n",
    "\n",
    "data[\"summary\"] = []\n",
    "\n",
    "for idx, (entry, accession) in enumerate(zip(result[\"summary\"][\"filter\"], accessions)):\n",
    "\n",
    "    sequence = data[\"uniprot\"][idx][\"sequence\"]\n",
    "    length = len(sequence)\n",
    "\n",
    "    publication = next((elem for elem in data[\"rcsb\"][idx][\"citation\"] if elem[\"pdbx_database_id_DOI\"]), None)\n",
    "    if publication:\n",
    "        publication = \"https://doi.org/\" + publication[\"pdbx_database_id_DOI\"]\n",
    "\n",
    "    offset = 0\n",
    "    if length != data[\"rcsb\"][idx][\"polymer_entities\"][0][\"entity_poly\"][\"rcsb_sample_sequence_length\"]:\n",
    "        if (offset := data[\"rcsb\"][idx][\"polymer_entities\"][0][\"entity_poly\"][\"pdbx_seq_one_letter_code_can\"].find(sequence)) == -1:\n",
    "            logging.warning(f\"Sequence mismatch for UniProt entry {accession}, PDB entry {entry}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "    hydropathy = [False] * length\n",
    "    disorder = [False] * length\n",
    "\n",
    "    for feature in data[\"rcsb\"][idx][\"polymer_entities\"][0][\"rcsb_polymer_entity_feature\"]:\n",
    "        values = feature[\"feature_positions\"][0][\"values\"]\n",
    "        if values is None: continue\n",
    "        start = max(0, feature[\"feature_positions\"][0][\"beg_seq_id\"] - 1 - offset)\n",
    "        end = min(length, (feature[\"feature_positions\"][0][\"end_seq_id\"] or start + len(values)) - offset)\n",
    "        match feature[\"type\"]:\n",
    "            case \"hydropathy\":\n",
    "                hydropathy[start:end] = values[:end-start]\n",
    "            case \"disorder\":\n",
    "                disorder[start:end] = values[:end-start]\n",
    "\n",
    "\n",
    "    cytoplasmic = [False] * length\n",
    "    exoplasmic = [False] * length\n",
    "    transmembrane = [False] * length\n",
    "    helix = [False] * length\n",
    "    sheet = [False] * length\n",
    "    turn = [False] * length\n",
    "\n",
    "    for feature in data[\"uniprot\"][idx][\"features\"]:\n",
    "        start = int(feature[\"begin\"]) - 1\n",
    "        end = int(feature[\"end\"])\n",
    "        match feature[\"type\"]:\n",
    "            case \"TOPO_DOM\":\n",
    "                if feature[\"description\"] == \"Cytoplasmic\":\n",
    "                    cytoplasmic[start:end] = [True] * (end - start)\n",
    "                elif feature[\"description\"] == \"Extracellular\":\n",
    "                    exoplasmic[start:end] = [True] * (end - start)\n",
    "            case \"TRANSMEM\":\n",
    "                transmembrane[start:end] = [True] * (end - start)\n",
    "            case \"HELIX\":\n",
    "                helix[start:end] = [True] * (end - start)\n",
    "            case \"TURN\":\n",
    "                turn[start:end] = [True] * (end - start)\n",
    "            case \"STRAND\":\n",
    "                sheet[start:end] = [True] * (end - start)\n",
    "\n",
    "\n",
    "    present = [False] * length\n",
    "\n",
    "    parser = FastMMCIFParser(auth_chains=False, auth_residues=False, QUIET=True)\n",
    "    structure: Structure.Structure = cast(Structure.Structure, parser.get_structure(entry, f\"./results/rcsb/{entry}.cif\"))\n",
    "\n",
    "    for chain in structure.get_chains():\n",
    "        if chain.id not in data[\"rcsb\"][idx][\"polymer_entities\"][0][\"rcsb_polymer_entity_container_identifiers\"][\"asym_ids\"]:\n",
    "            logging.warning(f\"Chain {chain.id} not found in UniProt entry {accession}, PDB entry {entry}\")\n",
    "            continue\n",
    "        for residue in chain:\n",
    "            if not is_aa(residue):\n",
    "                continue\n",
    "            position = residue.id[1] - 1 - offset\n",
    "            if position > 0 and position < length:\n",
    "                present[position] = True\n",
    "\n",
    "\n",
    "    description = data[\"alphafold\"][idx][\"uniprotDescription\"]\n",
    "    model = f\"{data[\"alphafold\"][idx][\"entryId\"]}-model_v{data[\"alphafold\"][idx][\"latestVersion\"]}\"\n",
    "\n",
    "    prediction: Structure.Structure = cast(Structure.Structure, parser.get_structure(entry, f\"./results/alphafold/{model}.cif\"))\n",
    "    confidence = [residue[\"CA\"].bfactor for residue in prediction.get_residues()]\n",
    "\n",
    "\n",
    "    data[\"summary\"].append({\n",
    "        \"accession\": accession,\n",
    "        \"entry\": entry,\n",
    "        \"model\": model,\n",
    "        \"description\": description,\n",
    "        \"sequence\": sequence,\n",
    "        \"length\": length,\n",
    "        \"publication\": publication,\n",
    "        \"hydropathy\": hydropathy,\n",
    "        \"disorder\": disorder,\n",
    "        \"confidence\": confidence,\n",
    "        \"cytoplasmic\": cytoplasmic,\n",
    "        \"exoplasmic\": exoplasmic,\n",
    "        \"helix\": helix,\n",
    "        \"sheet\": sheet,\n",
    "        \"turn\": turn,\n",
    "        \"present\": present\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAVE RESULTS\n",
    "\n",
    "json.dump(data[\"summary\"], open(\"./results/output.json\", \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### VISUALIZE SEARCH RESULTS\n",
    "\n",
    "sns.set_theme(style=\"white\", context=\"talk\")\n",
    "fig, ax = plt.subplots(figsize=(12, 12), dpi=600)\n",
    "\n",
    "diagram = EulerDiagram.from_sets(\n",
    "    sets=[set(search) for search in result[\"search\"].values()],\n",
    "    set_labels=[search.capitalize() for search in result[\"search\"].keys()],\n",
    "    set_colors=sns.color_palette(TUM_BLUE_GRADIENT, len(result[\"search\"])),\n",
    "    subset_labels=False,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "for patch in diagram.subset_artists.values():\n",
    "    patch.set_edgecolor(\"white\")\n",
    "    patch.set_linewidth(3)\n",
    "\n",
    "for label in diagram.set_label_artists:\n",
    "    label.set_fontsize(18)\n",
    "    label.set_fontweight(\"bold\")\n",
    "    label.set_color(\"black\")\n",
    "    label.set_path_effects([\n",
    "        path_effects.Stroke(linewidth=4, foreground=\"white\"),\n",
    "        path_effects.Normal()\n",
    "    ])\n",
    "\n",
    "plt.title(\"Search results\", fontsize=24, fontweight=\"bold\", pad=20)\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(\"./results/search.png\", bbox_inches=\"tight\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### VISUALIZE FILTER RESULTS\n",
    "\n",
    "sns.set_theme(style=\"white\", context=\"talk\")\n",
    "fig, ax = plt.subplots(figsize=(12, 12), dpi=600)\n",
    "\n",
    "counts = [len(result[\"summary\"][\"search\"])] + [len(filter) for filter in result[\"filter\"].values()]\n",
    "labels = [\"Search\"] + [filter.capitalize() for filter in result[\"filter\"].keys()]\n",
    "colors = cast(list, sns.color_palette(TUM_BLUE_GRADIENT, 2*len(counts)-1))\n",
    "\n",
    "height=0.8\n",
    "positions = list(range(len(labels), 0, -1))\n",
    "adjust = [(max(counts)-count)/2 for count in counts]\n",
    "\n",
    "for key, val, pos, adj, col in zip(labels, counts, positions, adjust, colors[::2]):\n",
    "    plt.barh(\n",
    "        y=pos,\n",
    "        width=val,\n",
    "        height=height,\n",
    "        left=adj,\n",
    "        color=col,\n",
    "        linewidth=3,\n",
    "        edgecolor=\"white\"\n",
    "    )\n",
    "    plt.text(\n",
    "        x=max(counts)/2,\n",
    "        y=pos,\n",
    "        s=str(val),\n",
    "        ha=\"center\",\n",
    "        va=\"center_baseline\",\n",
    "        fontsize=18,\n",
    "        fontweight=\"bold\",\n",
    "        color=\"white\" if (col[0] * 0.299 + col[1] * 0.587 + col[2] * 0.114) < 0.5 else \"black\"\n",
    "    )\n",
    "\n",
    "transition = [\n",
    "    (\n",
    "        [adjust[i], adjust[i+1], adjust[i+1] + counts[i+1], adjust[i] + counts[i]],\n",
    "        [positions[i] - height/2, positions[i+1] + height/2, positions[i+1] + height/2, positions[i] - height/2]\n",
    "    )\n",
    "    for i in range(len(counts)-1)\n",
    "]\n",
    "\n",
    "for tr, col in zip(transition, colors[1::2]):\n",
    "    plt.fill(tr[0], tr[1], color=col, linewidth=3, edgecolor=\"white\")\n",
    "\n",
    "ax.spines[\"left\"].set_visible(True)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.spines[\"bottom\"].set_visible(False)\n",
    "\n",
    "ax.spines[\"left\"].set_linewidth(2)\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks(positions, labels, fontsize=18, fontweight=\"bold\")\n",
    "\n",
    "plt.xlim(-max(counts)*0.03, max(counts))\n",
    "plt.ylim(1-height*0.6, len(labels)+height*0.6)\n",
    "\n",
    "plt.title(\"Filtering cascade\", fontsize=24, fontweight=\"bold\", pad=20)\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(\"./results/filter.png\", bbox_inches=\"tight\", format=\"png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "structure-query",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
